{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "orders = pd.read_csv('olist_orders_dataset.csv', usecols=['order_id', 'customer_id'])\n",
        "order_items = pd.read_csv('olist_order_items_dataset.csv', usecols=['order_id', 'product_id', 'order_item_id'])\n",
        "customers = pd.read_csv('olist_customers_dataset.csv', usecols=['customer_id', 'customer_unique_id', 'customer_zip_code_prefix'])\n",
        "\n",
        "# Reduce the dataset size by sampling\n",
        "sampled_orders = orders.sample(frac=0.05, random_state=42)  # Reduce to 5% of the dataset\n",
        "sampled_order_items = order_items[order_items['order_id'].isin(sampled_orders['order_id'])]\n",
        "sampled_customers = customers[customers['customer_id'].isin(sampled_orders['customer_id'])]\n",
        "\n",
        "# Merge the sampled data\n",
        "orders_items_customers = pd.merge(sampled_order_items, sampled_orders, on='order_id')\n",
        "orders_items_customers = pd.merge(orders_items_customers, sampled_customers, on='customer_id')\n",
        "\n",
        "# Save the sampled dataset to work with\n",
        "orders_items_customers.to_csv('sampled_orders_items_customers.csv', index=False)\n",
        "sampled_customers.to_csv('sampled_customers.csv', index=False)\n"
      ],
      "metadata": {
        "id": "6kpIiyxIHgfo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD, Dataset, Reader\n",
        "\n",
        "# Prepare the data\n",
        "def prepare_data(orders_items_customers):\n",
        "    # Use only the required columns to build the matrix\n",
        "    customer_product_matrix = orders_items_customers.pivot_table(\n",
        "        index='customer_unique_id',\n",
        "        columns='product_id',\n",
        "        values='order_item_id',\n",
        "        aggfunc='count',\n",
        "        fill_value=0\n",
        "    )\n",
        "    return customer_product_matrix\n",
        "\n",
        "# Train-test split and build dataset\n",
        "def train_test_split_data(data):\n",
        "    reader = Reader(rating_scale=(0, 1))\n",
        "    df = data.stack().reset_index(name='purchase')\n",
        "    df = df[df['purchase'] > 0]  # Remove zeros\n",
        "    data = Dataset.load_from_df(df[['customer_unique_id', 'product_id', 'purchase']], reader)\n",
        "    trainset = data.build_full_trainset()\n",
        "    return trainset\n",
        "\n",
        "# Collaborative Filtering with SVD\n",
        "def collaborative_filtering(trainset):\n",
        "    algo = SVD()\n",
        "    algo.fit(trainset)\n",
        "    return algo\n",
        "\n",
        "# Generate recommendations\n",
        "def generate_recommendations(algo, customer_product_matrix):\n",
        "    recommendations = {}\n",
        "    for customer in customer_product_matrix.index:\n",
        "        customer_recs = []\n",
        "        for product in customer_product_matrix.columns:\n",
        "            pred = algo.predict(customer, product).est\n",
        "            customer_recs.append((product, pred))\n",
        "        customer_recs.sort(key=lambda x: x[1], reverse=True)\n",
        "        recommendations[customer] = customer_recs[:5]  # Top 5 recommendations\n",
        "    return recommendations\n",
        "\n",
        "# Grouping by Location\n",
        "def group_by_location(customers, recommendations):\n",
        "    location_groups = customers.groupby('customer_zip_code_prefix')\n",
        "    location_recommendations = {}\n",
        "\n",
        "    for location, group in location_groups:\n",
        "        location_recs = {}\n",
        "        for customer in group['customer_unique_id']:\n",
        "            if customer in recommendations:\n",
        "                location_recs[customer] = recommendations[customer]\n",
        "        location_recommendations[location] = location_recs\n",
        "    return location_recommendations\n",
        "\n",
        "# Main function to execute the code\n",
        "def main():\n",
        "    # Load the sampled data\n",
        "    orders_items_customers = pd.read_csv('sampled_orders_items_customers.csv')\n",
        "    customers = pd.read_csv('sampled_customers.csv')\n",
        "\n",
        "    # Proceed with the existing logic\n",
        "    customer_product_matrix = prepare_data(orders_items_customers)\n",
        "    trainset = train_test_split_data(customer_product_matrix)\n",
        "    algo = collaborative_filtering(trainset)\n",
        "    recommendations = generate_recommendations(algo, customer_product_matrix)\n",
        "    location_recommendations = group_by_location(customers, recommendations)\n",
        "\n",
        "    print(\"Location-based Recommendations (sample):\")\n",
        "    for location, recs in list(location_recommendations.items())[:3]:\n",
        "        print(f\"Location: {location}, Recommendations: {recs}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGmwws7pM4Zv",
        "outputId": "274c1d51-e510-43f2-e02f-62f6f1d42f52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location-based Recommendations (sample):\n",
            "Location: 1007, Recommendations: {'aa1c9c908a46198cf8b8fdc5c8037688': [('001b72dfd63e9833e8c02742adf472e3', 1), ('0030026a6ddb3b2d1d4bc225b4b4c4da', 1), ('003a31970fea14fffe92ac856b8a9b97', 1), ('006baa9a5b8f95895f15273a35bc2664', 1), ('008cff0e5792219fae03e570f980b330', 1)]}\n",
            "Location: 1008, Recommendations: {'964eb1b98713e4527eb11bce9a0ac1fe': [('001b72dfd63e9833e8c02742adf472e3', 1), ('002159fe700ed3521f46cfcf6e941c76', 1), ('003a31970fea14fffe92ac856b8a9b97', 1), ('006baa9a5b8f95895f15273a35bc2664', 1), ('008cff0e5792219fae03e570f980b330', 1)]}\n",
            "Location: 1011, Recommendations: {'35052a34c8cddade15549afde5580e83': [('001b72dfd63e9833e8c02742adf472e3', 1), ('002159fe700ed3521f46cfcf6e941c76', 1), ('0030026a6ddb3b2d1d4bc225b4b4c4da', 1), ('003a31970fea14fffe92ac856b8a9b97', 1), ('006baa9a5b8f95895f15273a35bc2664', 1)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r06Zxsh0eAnq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}